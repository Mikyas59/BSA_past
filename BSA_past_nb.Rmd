---
title: "BSA Data 2013-2018"
author: "BOARDSOURCE"
date: "`r Sys.Date()`"
output: 
  html_document: 
    df_print: paged
    highlight: tango
    theme: flatly
---

```{r libraries, warning=FALSE, include=FALSE}
library(tidyverse)
library(flexdashboard)
library(psych)
library(qualtRics)
library(usethis)
library(sjlabelled)
library(stringr)
library(lubridate)
library(rio)
library(data.table)
library(DT)

#use_github(protocol = "https", auth_token = Sys.getenv("GITHUB_PAT"))
```


```{r import, include=FALSE}
#BSA_past18<- read_survey("H:/BSA/BSA Data 2013-2018.csv")
BSA_past18 <- read_survey("C:/Users/mikyas.duga/OneDrive - BoardSource/Documents/R/BSA_past/BSA Data 2013-2018.csv")

#questions<-data.frame(names(BSA_past18), get_label(BSA_past18))

##Look at how many finished survey/level of progress
#describe(BSA_past18$Progress)

##Make a copy of original file. 
BSA_past18.2 <- BSA_past18
#saveRDS(BSA_past18.2, file = "BSA_past18.2.rds") 

##Extract date from datetime values in EndDate variable. 
#BSA_past18.2 <- separate(BSA_past18.2, EndDate, into = c("Survey_enddate", "surveyendtime"), sep = " ", remove = FALSE, convert = TRUE)

##Extract year values from survey _enddate variable and delete extraneous values. 

#BSA_past18.2$survey_year <- str_sub(BSA_past18.2$Survey_enddate, -4, -1)

#BSA_past18.2 <- BSA_past18.2 %>%
 # select(-c(surveyendtime))
  

##overall 14,024 responses. Breakdown number of responses by year. 
# BSA_past18.2 %>%
# group_by(survey_year)%>%
# count(n())

  
```


```{r wrangle, warning=TRUE}
##How many times did orgs take survey?
#BSA_past18.2 %>%
 # group_by(Org_Name, survey_year) %>%
# count(n())
##There may be a number of cases where only one participant took survey in a particular year (likely a case of different survey end dates)
##A number of surveys without org names. could be derived from ImportedSurveyName. 

##Assign org-name for those without an orgname derived from the Importedsurveyname. 
##58 observations with no orgname.  
#BSA_past18.2 %>%
#  filter(is.na(Org_Name))

BSA_past18.2$Org_Name <- if_else(is.na(BSA_past18.2$Org_Name), str_sub(BSA_past18.2$ImportedFromSurveyName, 1, -5), BSA_past18.2$Org_Name)

##for orgname==Edgewood, survey year =2014. orgname==PENCIL, year==2014. 
##for orgname==National CASA association Pennsylvania, year ==2017

##New survey year variable adopted from the ImportedfromsurveyName varialbe. 

##BSA_past18.2$survey_year2 <- str_sub(BSA_past18.2$ImportedFromSurveyName, -4, -1)

BSA_past18.2 <- BSA_past18.2%>%
  mutate(survey_year2 = case_when(
    BSA_past18.2$Org_Name == "Edgewood" ~ "2014",
    BSA_past18.2$Org_Name == "PENCIL" ~ "2014",
    BSA_past18.2$Org_Name == "National CASA Association - Pennsylvania" ~ "2017",
    TRUE ~ str_sub(BSA_past18.2$ImportedFromSurveyName, -4, -1))
  )

##Fit typo of year 2106 to 2016. 
BSA_past18.2$survey_year2 <- if_else(BSA_past18.2$survey_year2 == "2106", "2016", BSA_past18.2$survey_year2)

ftable(BSA_past18.2$survey_year2)

##Get rid of phrases "Board Assessment" and "BSA" for orgnames derived from the importedsurveyname 
# table(str_which(BSA_past18.2$Org_Name, "BSA"))
# table(str_detect(BSA_past18.2$Org_Name, "Board Assessment"))

BSA_past18.2$Org_Name <- str_remove(BSA_past18.2$Org_Name, "BSA" )
BSA_past18.2$Org_Name <- str_remove(BSA_past18.2$Org_Name, "Board Assessment")


# table(str_detect(BSA_past18.2$Org_Name, "BSA"))

##No. of distinct organizations ##preliminary
BSA_past18.2 %>%
  select(Org_Name)%>%
  n_distinct()

##How many times have orgs taken the survey 
BSA_past18.4 <- BSA_past18.2 %>%
  group_by(Org_Name)%>%
  arrange(Org_Name)%>%
  distinct(survey_year2)

##Need a way to limit a copy data set to just orgs who have taken the survey more than once. 
##74 organizations have taken the survey more than once. 
BSA_past_multi <- BSA_past18.4 %>%
  count(n()) %>%
  filter(n>1)
BSA_past_multi

```

```{r basic board performance summary}
#Overall summary of board performance aka Benchmarking. 

##Set 99 to missing. 
BSA_past18.2 <- BSA_past18.2 %>%
  na_if(99)

#attach(BSA_past18.2)
#Mission <- BSA_past18.2 %>% 
 #  select(starts_with("M_A1"))
#Mission <- colnames(Mission)  ##Variables assessing performance related to mission. 
#Strategy <- BSA_past18.2 %>%
 # select(starts_with("ST_A2"))
#Strategy <- colnames(Strategy)

#Fund <- BSA_past18.2 %>%
 # select(F_B1_6_strategy:F_B1_11_fulfill)
#Fund <- colnames(Fund)

#image <- BSA_past18.2 %>%
 # select(F_B1_1_image:F_B1_5_sources, F_B1_12_impact:F_B1_13_educate)

##Probably enough for now. 

##Benchmark values for mission area. 
# mission_bench <- BSA_past18.2 %>%
#   select(starts_with("M_A1"))%>%
#   summarise_all(mean, na.rm = TRUE)
# 
# ##Create bar chart showing means on mission area. 
# mission_bench <- data.frame(mission_bench)
# mission_bench <- t(mission_bench)
# mission_bench <- data.frame(mission_bench)
# mission_bench$area <- row.names(mission_bench) 
# 
# ggplot(data = mission_bench) + 
#   geom_bar(aes(y=area, x=mission_bench), stat = "identity", fill ="lightblue"
#            )  
```


```{r composite scores}
### Create composite scores for the different areas (mission, strategy, public image, funding, board composition, program oversight, financial oversight, CEO supervision, board structure and meetings.)

BSA_past18.3 <-  BSA_past18.2 %>%
  mutate(mission_composite = rowMeans(select(BSA_past18.2,
                                             starts_with("M_A1")), na.rm = TRUE)) %>%
  
  mutate(stragey_composite = rowMeans(select(BSA_past18.2,
                                             starts_with("ST_A2")), na.rm = TRUE)) %>%
  
  mutate(image_composite = rowMeans(select(BSA_past18.2,F_B1_1_image:F_B1_5_sources, F_B1_12_impact, F_B1_13_educate), na.rm = TRUE)) %>%
  
  mutate(fund_composite = rowMeans(select(BSA_past18.2,F_B1_6_strategy:F_B1_11_fulfill), na.rm = TRUE)) %>%
  
  mutate(brdcmp_composite = rowMeans(select(BSA_past18.2,BC_B2_1_lead:BC_B2_9_diverse), na.rm = TRUE)) %>%
  
  mutate(program_composite = rowMeans(select(BSA_past18.2,
                                             PO_C1_1_know:PO_C1_6_impact), na.rm = TRUE)) %>%
  
  mutate(Fidoversight_composite = rowMeans(select(BSA_past18.2,
                                                  FO_C2_1_priorities:FO_C2_8_F990), na.rm = TRUE)) %>%
  
  mutate(CEO_supervise_composite = rowMeans(select(BSA_past18.2, 
                                                   CO_C3_1_trust:CO_C3_7_depart), na.rm = TRUE)) %>%
  
  mutate(Brd_str_composite = rowMeans(select(BSA_past18.2,
                                             BS_D1_1_legal:BS_D1_8_comm), na.rm = TRUE)) %>%
  
  mutate(meet_composite = rowMeans(select(BSA_past18.2, MT_D2_1_trust:MT_D2_7_engage), na.rm = TRUE))
  
  
BSA_past18.3 <- BSA_past18.3 %>%
  mutate(round(across(mission_composite:meet_composite), digits = 2))
  
  
```


```{r multiple takers}
###Compare composite scores (last occasion vs benchmark for repeat takers)
##identify repeat takers in a copy of the working data set. 

BSA_past18.5 <- BSA_past18.3 %>%
    mutate(user = case_when(
    BSA_past18.3$Org_Name %in% BSA_past_multi$Org_Name ~ "repeat-taker",
    TRUE ~ "one-time")
  )

#table(BSA_past18.5$user)
##Summarize means based on user freq. (org is one time BSA-user or repeat taker)
table1 <- BSA_past18.5 %>%
  group_by(user)%>%
  summarize(Average_mission_composite = mean(mission_composite, na.rm = TRUE),
            Average_strategy_composite = mean(stragey_composite, na.rm = TRUE), 
            Average_image_composite = mean(image_composite, na.rm = TRUE), 
            Average_fundraising_comp = mean(fund_composite, na.rm = TRUE), 
            Avg_brd_composition_comp = mean(brdcmp_composite, na.rm = TRUE),
            Avg_programoversight_comp = mean(program_composite, na.rm = TRUE),
            Avg_fiduciary_comp = mean(Fidoversight_composite, na.rm = TRUE), 
            Avg_CEOoversight_comp = mean(CEO_supervise_composite, na.rm = TRUE), 
            Avg_Brdstructure_comp = mean(Brd_str_composite, na.rm = TRUE),
            Avg_Brdmeeting_comp = mean(meet_composite, na.rm = TRUE)
            )
table1 <- data.frame(table1) 
table2 <- data.frame(t(table1[-1]))
colnames(table2) <- table1[, 1]
table2 

##perform all associated t-tests. 
test1 <- t.test(BSA_past18.5$mission_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)  ##Significant difference

test2 <- t.test(BSA_past18.5$stragey_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)  ##Significant difference

test3 <- t.test(BSA_past18.5$image_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test4 <- t.test(BSA_past18.5$fund_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test5 <- t.test(BSA_past18.5$brdcmp_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test6 <- t.test(BSA_past18.5$program_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test7 <- t.test(BSA_past18.5$Fidoversight_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test8 <- t.test(BSA_past18.5$CEO_supervise_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test9 <- t.test(BSA_past18.5$Brd_str_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

test10 <- t.test(BSA_past18.5$meet_composite ~ BSA_past18.5$user, data = BSA_past18.5, na.rm = TRUE)

result_p <- c(test1$p.value, test2$p.value, test3$p.value, test4$p.value, test5$p.value, test6$p.value, test7$p.value, test8$p.value, test9$p.value, test10$p.value)

result_ts <- c(test1$statistic, test2$statistic, test3$statistic, test4$statistic, test5$statistic, test6$statistic, test7$statistic, test8$statistic, test9$statistic, test10$statistic)

table3 <- cbind.data.frame(table2, result_ts, result_p)
table3 <- table3 %>%
  rename('Test Statistic' = result_ts,
         'P-value' = result_p)
table3

```

```{r multiple takers2}
###compare composite scores at first occasion and last occasion for repeat takers. 
##create a data-set with just multiple takers, and indicate first-time surveys and last-recorded surveys. 
BSA_past18.6 <- BSA_past18.5 %>%
  filter(user == "repeat-taker")

BSA_past18.6 <- BSA_past18.6 %>%
  group_by(Org_Name)%>%
  mutate(occasion = case_when(
    survey_year2 == min(survey_year2, na.rm = TRUE) ~ "first_time",
    survey_year2 == max(survey_year2, na.rm = TRUE) ~ "last_occasion",
    TRUE ~ "Neither")
    )


##checking work here. looks fine. 
#BSA_past18.6 %>%
 # group_by(Org_Name, survey_year2)%>%
  #arrange(Org_Name) %>%
  #select(Org_Name, survey_year2, occasion)

##Compare average composite scores between first occasion and last occasion. 
table3 <- BSA_past18.6 %>%
  group_by(occasion)%>%
  summarize(Average_mission_composite = mean(mission_composite, na.rm = TRUE),
            Average_strategy_composite = mean(stragey_composite, na.rm = TRUE), 
            Average_image_composite = mean(image_composite, na.rm = TRUE), 
            Average_fundraising_comp = mean(fund_composite, na.rm = TRUE), 
            Avg_brd_composition_comp = mean(brdcmp_composite, na.rm = TRUE),
            Avg_programoversight_comp = mean(program_composite, na.rm = TRUE),
            Avg_fiduciary_comp = mean(Fidoversight_composite, na.rm = TRUE), 
            Avg_CEOoversight_comp = mean(CEO_supervise_composite, na.rm = TRUE), 
            Avg_Brdstructure_comp = mean(Brd_str_composite, na.rm = TRUE),
            Avg_Brdmeeting_comp = mean(meet_composite, na.rm = TRUE)
            )
table3 <- data.frame(table3) 
table4 <- data.frame(t(table3[-1]))
colnames(table4) <- table3[, 1]
table4 
##Somehow the middle assessments tend to have higher average scores than both first occasion and last occasion. perhaps make an average comparing first-time takers vs those who are taking it a second time or more.  

##perform all associated t-tests. 
# test1.2 <- t.test(BSA_past18.6$mission_composite ~ BSA_past18.6$occasion, data = BSA_past18.6, na.rm = TRUE)  
# 
# test2.2 <- t.test(BSA_past18.6$stragey_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)  
# 
# test3.2 <- t.test(BSA_past18.6$image_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test4.2 <- t.test(BSA_past18.6$fund_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test5.2 <- t.test(BSA_past18.6$brdcmp_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test6.2 <- t.test(BSA_past18.6$program_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test7 <- t.test(BSA_past18.6$Fidoversight_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test8 <- t.test(BSA_past18.6$CEO_supervise_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test9 <- t.test(BSA_past18.6$Brd_str_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)
# 
# test10 <- t.test(BSA_past18.6$meet_composite ~ BSA_past18.6$user, data = BSA_past18.6, na.rm = TRUE)


```



```{r dei}
###see if there are any trends in dei areas. 
summary(BSA_past18.5$BC_B2_2_gaps)
table5 <- BSA_past18.5 %>%
  group_by(survey_year2)%>%
  summarise(mean = mean(BC_B2_2_gaps, na.rm = TRUE),
            median = median(BC_B2_2_gaps, na.rm = TRUE),
            IQR = IQR(BC_B2_2_gaps, na.rm = TRUE))
table5
##no discernible trend over time.             


##the previous measure (BC_B2_gaps) is not as important because it doesn't only measure dei. 
summary(BSA_past18.5$BC_B2_9_diverse)  ##8330 non-responses. perhaps this was introduced at a later time.  

BSA_past18.5%>%
  filter(survey_year2 >= 2016)%>%
  summarise(overall_mean = mean(BC_B2_9_diverse, na.rm = T),
            overall_median = median(BC_B2_9_diverse, na.rm = T), 
            overall_sd = sd(BC_B2_9_diverse, na.rm = T),
            quantile(BC_B2_9_diverse, na.rm = T))
##1st quartile =2 & 3rd quartile =4. 

##Average scores by year summary
BSA_past18.5 %>%
  group_by(survey_year2)%>%
  summarise(mean(BC_B2_9_diverse, na.rm = T),
            sd = sd(BC_B2_9_diverse, na.rm = T), 
            sum(n()), 
            no_of_respondents = sum(!is.na(BC_B2_9_diverse))
          )
##no observable trend by survey year. 


##Summarizing the role of survey participants. (1=CEO, 2=BC, 3=Brd-member)
table(BSA_past18.5$BSA_Role) ##821 CEOs 

BSA_past18.5 %>%
  filter(BSA_Role == 1)%>%
  summarise( mean = mean(ORGD_5_TEXT, na.rm = T),
             median = median(ORGD_5_TEXT, na.rm = T),
             quantile(ORGD_5_TEXT, na.rm = T),
             min = min(ORGD_5_TEXT, na.rm = T),
             missing = sum(is.na(ORGD_5_TEXT)))
##only 380 respondents. don't know if this is usable. trying to see summary of org incomes. A lot of non-respondents. 

```



```{r PDBL}
###PDBL related items. 
summary(BSA_past18.5$ST_A2_4_change) ##assessing and responding to changes in the env't. 
summary(BSA_past18.5$F_B1_2_leaders) ##connecting w/ comm. leaders
summary(BSA_past18.5$F_B1_3_network) ##networking to establish collaboration w/ other org. 

##compare the bottom quarter and top quarter diversity performances wrt connections with community leaders. 
BSA_past18.5 <- BSA_past18.5%>%
  mutate(div_quar = case_when(
    BC_B2_9_diverse <= 2 ~ 'bottom',
    BC_B2_9_diverse ==4 ~ 'top')
    )

# BSA_past18.5%>%
#   select(BC_B2_9_diverse, div_quar)

table6 <- BSA_past18.5 %>%
  group_by(div_quar)%>%
  summarise(mean = mean(F_B1_2_leaders, na.rm = T),
            sum(n()))
table6

dfdiv <- BSA_past18.5%>%
  filter(!is.na(div_quar))

testdiv <- t.test(F_B1_2_leaders ~ div_quar, data = dfdiv)
tablediv <- cbind(table6, testdiv$statistic, testdiv$p.value)
tablediv

##Significant difference between those that report a high performance in diversity vs those that report a low performance in divesity wrt connections with community leaders. 

##comparing diversity vs responding to change in the environment 
BSA_past18.5 %>%
  group_by(div_quar)%>%
  summarise( mean = mean(ST_A2_4_change, na.rm = T), 
             sum(n()))

##Also appears to be a substantial difference. Need a test. 

## A general comparison in performance between top-diversity and bottom-diversity groups (comparison in composite scores). 
comp_perf <- dfdiv %>%
  select(mission_composite:div_quar)
  
describeBy(comp_perf, group = comp_perf$div_quar, mat = TRUE)
##orgs that indicate a high performance in diversity also tend to consistently report high performance across all areas (in composite scores). 


```



```{r Budget info}
##Taking another look at organizational budget information.
##Avoid multiple appearances from a single org and first check to see federated orgs. 
table(BSA_past18.5$ORGD_9) ##1=NO, 2=Yes

##Summary for non-federated orgs among CEOs.


##Identifying CEOs from the data-set here. The BSA_Role variable classifies a lot of board members as CEOs likely because of the multiple choice wording. Created a classification of CEOs using the 'chiefexec' variable comprised of respondents whose roles were one of the following: CEO, Director or Executive Director.  

###***Don't know which role question is more reliable. 
##Data-set with chiefexec variable. 
BSA_past18.7<- BSA_past18.5 %>%
  mutate(cheifexec = case_when(
    str_starts(Role, "CEO") ~ 1, 
    Role == "Director" ~ 1, 
    Role == "Executive Director" ~ 1, 
    TRUE ~ 0)
    )

##Save this file as an rds file. 
saveRDS(BSA_past18.7, "BSA_past18.7.rds")

# BSA_past18.5%>%
#   filter(BSA_Role == 1)%>%
#   summarise(mean = mean(ORGD_5_TEXT, na.rm = T),
#             sd = sd(ORGD_5_TEXT, na.rm = T),
#             miss = sum(is.na(ORGD_5_TEXT)),
#             resp = sum(!is.na(ORGD_5_TEXT)))
  

# BSA_past18.7 %>%
#   filter(cheifexec == 1)%>%
#   summarise(mean = mean(ORGD_5_TEXT, na.rm = T),
#             sd = sd(ORGD_5_TEXT, na.rm = T),
#             miss = sum(is.na(ORGD_5_TEXT)),
#             resp = sum(!is.na(ORGD_5_TEXT)))

 ##more responses under cheifexec option. Removing the cheifexec filter will only produce 5 more responses. 
 ##Will stick with the cheifexec variable for now. 

##Select CEOs from non-federated orgs, 

BSA_past18.7 %>%
  filter(ORGD_9==1 & cheifexec == 1)%>%
  group_by(Org_Name)%>%
  arrange(Org_Name, desc(survey_year2))%>%
  select(Org_Name, survey_year2, ORGD_5_TEXT)


##When there are multiple survey-years available for an org, take the average. Keep only one response for a single organization.  
BSA_bud2 <- BSA_past18.7 %>%
  filter(ORGD_9==1 & cheifexec == 1)%>%
  group_by(Org_Name)%>%
  arrange(Org_Name, desc(survey_year2))%>%
  mutate(average_budget = mean(ORGD_5_TEXT, na.rm = T))%>%
  distinct(Org_Name, .keep_all = T)

summary(BSA_bud2$average_budget)  ###only 280 responses from 454. 

##How many organizations have a budget between 50,000 and 20,000,000 (to limit the data-set to be more representative)
# BSA_bud2 %>%
#   filter(average_budget >= 50000 & average_budget <= 20000000)%>%
#   summarise(mean = mean(average_budget, na.rm = T),
#             quantile(average_budget, na.rm = T),
#             no_res = sum(n()))

BSA_bud2 %>%
  group_by(Org_Name)%>%
  arrange(Org_Name, desc(survey_year2))%>%
  distinct(Org_Name, .keep_all = T)%>%
  ungroup()%>%
  filter(average_budget >= 50000 & average_budget <= 20000000)%>%
  summarise(mean = mean(average_budget, na.rm = T),
            quantile(average_budget, na.rm = T),
            median = median(average_budget, na.rm = T),
            no.of.res = sum(n()))

##Had to use the group and ungroup commands to get it to work properly. Median budget is at approximately 3.5M and mean 5.6M. May be more reasonable.
##Grouping by IRS classification doesn't yield useful info. most organizations are 501c3s. Not many observations for other classes. 


```



```{r Org characteristics}
##Data-set with CEO responses only. Kept the last response per organization. 
BSA_past18.8 <- BSA_past18.7 %>%
  filter(cheifexec == 1)%>%
  group_by(Org_Name)%>%
  arrange(Org_Name, desc(survey_year2))%>%
  distinct(Org_Name, .keep_all = T)



##Summary of mission areas, IRS class, year founded, no. of FTE employees
table(BSA_past18.8$ORGD_2)

table(BSA_past18.8$ORGD_1) ##IRS class. 1=PC, 2=Private foundation

table(BSA_past18.8$ORGD_3) ##yr founded

summary(BSA_past18.8$ORGD_7) ##No. of FTE employees 

summary(BSA_past18.8$BDI_1)  ##No. of voting board members. 

# Still dealing with very large organizations with an average of 233 employees (median = 34). Most orgs are 501c3.

##Summary of overall effectiveness (asked to all respondents - very dissatisfied to very satisfied) 
summary(BSA_past18.5$BCE_1_2_effective)  ##average respondent is 'satisfied.'
prop.table(table(BSA_past18.5$BCE_1_2_effective))*100

n_distinct(BSA_past18.5$RecipientEmail)  ##No way to identify individuals who have taken the survey multiple times except for perhaps IP address. 

n_distinct(BSA_past18.5$IPAddress)  ##12125 unique IP addresses. 

summary(BSA_past18.5$BCE_1_4_rewarding) ##Most are satisfied or very satisfied.
prop.table(table(BSA_past18.5$BCE_1_4_rewarding))*100

```

